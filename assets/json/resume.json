{
  "basics": {
    "name": "Zach Nussbaum",
    "label": "Machine Learning Engineer",
    "email": "zanussbaum@gmail.com",
    "url": "https://www.linkedin.com/in/zach-nussbaum/",
    "summary": "Experienced Machine Learning Engineer with a focus on natural language processing, computer vision, and large-scale model deployment.",
    "location": {},
    "profiles": [
      {
        "network": "LinkedIn",
        "username": "zach-nussbaum",
        "url": "https://www.linkedin.com/in/zach-nussbaum/"
      },
      {
        "network": "GitHub",
        "username": "zanussbaum",
        "url": "https://github.com/zanussbaum"
      }
    ]
  },
  "work": [
    {
      "name": "Nomic AI",
      "position": "Principal Machine Learning Engineer",
      "location": "New York, NY",
      "url": "",
      "startDate": "2023-03-01",
      "endDate": "",
      "summary": "Leading the Embedding Team and implementing state-of-the-art embedding models.",
      "highlights": [
        "Implemented Nomic Embed, powering Atlas embedding space visualization for text and multimodal applications",
        "Trained and deployed Nomic Embed Text, outperforming OpenAI with 15M+ monthly downloads",
        "Trained Nomic Embed Vision, the first multimodal embedding space performing highly on both multimodal and text embedding benchmarks",
        "Deployed Nomic Embed models serving as backbone to Atlas, handling billions of tokens monthly"
      ]
    },
    {
      "name": "Deep Genomics",
      "position": "Machine Learning Engineer",
      "location": "Remote",
      "url": "",
      "startDate": "2022-01-01",
      "endDate": "2023-03-01",
      "summary": "Focused on genomics and RNA research using machine learning techniques.",
      "highlights": [
        "Reimplemented and improved DeepMind gene expression model in Tensorflow by 15-30% on TPUs",
        "Led research on representation learning for chemical modifications of RNA molecules using Transformer based architectures",
        "Helped standardize and run highly distributed training of attention-based models across many GPUs and TPUs",
        "Reduced latency of large Deep Learning models by ~16x utilizing model distillation and TensorRT",
        "Ported Maximal Update Parameterization to Tensorflow for zero-shot hyperparameter transfer across model width and depth"
      ]
    },
    {
      "name": "Amazon",
      "position": "Machine Learning Engineer",
      "location": "Seattle, Washington",
      "url": "",
      "startDate": "2020-09-01",
      "endDate": "2021-12-01",
      "summary": "Worked on Alexa Speech Speaker ID model and optimized AWS infrastructure.",
      "highlights": [
        "Maintained and improved evaluation pipelines for Alexa Speech Speaker ID model for 25M+ global consumers",
        "Improved runtime of large PySpark processing jobs by 25% and reduced job failures by 50%",
        "Drove redesign and engineering for Alexa SpeakerID weekly evaluation pipeline, reducing manual work by 75%",
        "Optimized AWS EMR clusters for ML Ad Ranking Team, reducing operational costs by 50% leveraging AWS Lambda and AWS Event Bridge"
      ]
    }
  ],
  "education": [
    {
      "institution": "Davidson College",
      "location": "Davidson, NC",
      "area": "Computer Science",
      "studyType": "Bachelor of Science",
      "startDate": "2016-08-01",
      "endDate": "2020-05-01",
      "score": "",
      "courses": []
    }
  ],
  "awards": [],
  "references": []
}
